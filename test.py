import json
from typing import Optional, Callable, List, Dict, Any, TypedDict, Union
from rich.console import Console
from openai import AsyncOpenAI, AsyncStream
from openai.types.chat import ChatCompletionMessageParam, ChatCompletionChunk

console = Console()

# ==================== ç±»å‹å®šä¹‰ ====================
class ToolFunction(TypedDict):
    name: str
    arguments: str

class ToolCall(TypedDict):
    id: str
    type: str
    function: ToolFunction

class Message(TypedDict, total=False):
    role: str
    content: Optional[str]
    tool_calls: Optional[List[ToolCall]]
    tool_call_id: Optional[str]  # tool è§’è‰²æ¶ˆæ¯ä½¿ç”¨

# ==================== å‡è®¾çš„å¯¼å…¥ï¼ˆéœ€æ ¹æ®å®é™…é¡¹ç›®è°ƒæ•´ï¼‰ ====================
# from .config import create_openai_client, get_system_prompt, Message, ToolCall
# from .tools import TOOLS, run_tool, parse_tool_arguments

def get_system_prompt() -> str:
    return "You are a helpful assistant."

def create_openai_client(api_key: str, base_url: str) -> AsyncOpenAI:
    return AsyncOpenAI(api_key=api_key, base_url=base_url)

# å·¥å…·å®šä¹‰ç¤ºä¾‹
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "bash",
            "description": "Execute shell command",
            "parameters": {"type": "object", "properties": {}}
        }
    }
]

async def run_tool(name: str, args: Dict[str, Any], workdir: str) -> str:
    """å·¥å…·æ‰§è¡Œå‡½æ•°ï¼ˆç¤ºä¾‹ï¼‰"""
    return f"Executed {name} with {args} in {workdir}"

def parse_tool_arguments(tool_call: ToolCall) -> Dict[str, Any]:
    try:
        return json.loads(tool_call["function"]["arguments"])
    except (json.JSONDecodeError, KeyError):
        return {}

# ==================== æ ¸å¿ƒç±» ====================
class NanoSession:
    def __init__(self, api_key: str, base_url: str, model: str, workdir: str):
        self.client = create_openai_client(api_key, base_url)
        self.workdir = workdir
        self.model = model
        self.history: List[Message] = [
            {"role": "system", "content": get_system_prompt()}
        ]

    async def chat(
        self, 
        user_input: str, 
        on_chunk: Optional[Callable[[str], None]] = None
    ) -> None:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œæ”¯æŒæµå¼è¾“å‡ºå’Œå·¥å…·è°ƒç”¨
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            on_chunk: å¯é€‰çš„å›è°ƒå‡½æ•°ï¼Œç”¨äºå®æ—¶æ¥æ”¶æµå¼è¾“å‡º
        """
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self.history.append({"role": "user", "content": user_input})

        while True:
            console.print("[dim]ğŸ¤– Thinking...[/]")

            # å‘èµ·æµå¼è¯·æ±‚
            stream = await self.client.chat.completions.create(
                model=self.model,
                messages=self.history,  # type: ignore
                tools=TOOLS,  # type: ignore
                tool_choice="auto",
                stream=True
            )

            full_content = ""
            has_tool_calls = False
            tool_calls_map: Dict[str, ToolCall] = {}

            # å¤„ç†æµå¼å“åº”
            async for chunk in stream:
                delta = chunk.choices[0].delta if chunk.choices else None
                
                if not delta:
                    continue

                # å¤„ç†æ–‡æœ¬å†…å®¹
                if delta.content:
                    full_content += delta.content
                    if on_chunk:
                        on_chunk(delta.content)

                # å¤„ç†å·¥å…·è°ƒç”¨
                if delta.tool_calls:
                    has_tool_calls = True
                    for tc in delta.tool_calls:
                        tc_id = tc.id
                        tc_func = tc.function
                        
                        if tc_id:
                            # æ–°çš„å·¥å…·è°ƒç”¨
                            if tc_id in tool_calls_map:
                                # è¿½åŠ å‚æ•°
                                if tc_func and tc_func.arguments:
                                    tool_calls_map[tc_id]["function"]["arguments"] += tc_func.arguments
                            else:
                                # åˆ›å»ºæ–°æ¡ç›®
                                tool_calls_map[tc_id] = {
                                    "id": tc_id,
                                    "type": "function",
                                    "function": {
                                        "name": tc_func.name if tc_func else "",
                                        "arguments": tc_func.arguments if tc_func else ""
                                    }
                                }
                        elif tc_func and tc_func.arguments:
                            # æ—  id çš„å‚æ•°ç‰‡æ®µï¼ˆDeepSeek è¡Œä¸ºï¼‰
                            # è¿½åŠ åˆ°æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨
                            if tool_calls_map:
                                last_key = list(tool_calls_map.keys())[-1]
                                tool_calls_map[last_key]["function"]["arguments"] += tc_func.arguments

            # æ„é€ åŠ©æ‰‹æ¶ˆæ¯
            message: Message = {
                "role": "assistant",
                "content": full_content if full_content else None,
                "tool_calls": list(tool_calls_map.values()) if has_tool_calls else None
            }

            self.history.append(message)

            # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå®ƒä»¬å¹¶ç»§ç»­å¾ªç¯
            if has_tool_calls and message.get("tool_calls"):
                console.print()

                for tool_call in message["tool_calls"]:
                    args = parse_tool_arguments(tool_call)
                    result = await run_tool(
                        tool_call["function"]["name"],
                        args,
                        self.workdir
                    )
                    
                    console.print("[blue]ğŸ‘ OBSERVE[/]")
                    console.print(f"[dim]{result}[/]")
                    console.print()

                    # æ·»åŠ å·¥å…·ç»“æœåˆ°å†å²
                    self.history.append({
                        "role": "tool",
                        "tool_call_id": tool_call["id"],
                        "content": result
                    })

                console.print("[magenta]ğŸ”„ REPEAT[/]")
                continue  # ç»§ç»­å¾ªç¯ï¼Œå°†å·¥å…·ç»“æœå‘ç»™æ¨¡å‹

            break  # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸ

    def get_history(self) -> List[Message]:
        """è·å–å¯¹è¯å†å²"""
        return self.history

    def clear_history(self) -> None:
        """æ¸…ç©ºå†å²ï¼Œä¿ç•™ç³»ç»Ÿæç¤ºè¯"""
        self.history = [{"role": "system", "content": get_system_prompt()}]

# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================
async def main():
    session = NanoSession(
        api_key="sk-xxx",
        base_url="https://api.openai.com/v1",
        model="gpt-4",
        workdir="/tmp"
    )
    
    def print_chunk(text: str):
        print(text, end="", flush=True)
    
    await session.chat("æŸ¥çœ‹å½“å‰ç›®å½•æ–‡ä»¶", on_chunk=print_chunk)
    print("\n\nå†å²è®°å½•:", session.get_history())

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())